{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luizaclara/KNNtitanic/blob/main/Trabalho_02ICD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynOzyZkzWxUc"
      },
      "source": [
        "https://www.kaggle.com/c/titanic/data\n",
        "\n",
        "https://github.com/datasciencedojo/datasets/blob/master/titanic.csv\n",
        "\n",
        "PassengerId\n",
        "Survived\n",
        "Pclass\n",
        "Name\n",
        "Sex\n",
        "Age\n",
        "SibSp\n",
        "Parch\n",
        "Ticket\n",
        "Fare\n",
        "Cabin\n",
        "Embarked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "YtZnvSF_WlnV"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "QlMfRUOrY3Pb"
      },
      "outputs": [],
      "source": [
        "class KNN ():\n",
        "  def __init__(self,k=3):\n",
        "    self.k = k\n",
        "\n",
        "  def fit(self,X,Y):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def predict_one(self,x):\n",
        "    distances = sorted(self.distance(x),lambda d:d [0])[:self.k]\n",
        "\n",
        "    tags_count = {} # {tag : (contagem , soma das distancias)}\n",
        "    \n",
        "    for dist, tag in distances:\n",
        "      if tag not in tags_count:\n",
        "        count[tag] = (0, 0)\n",
        "      count[tag] = (count[tag][0] + 1, count[tag][1] + dist )\n",
        "\n",
        "    # ordena em ordem decrescente a contagem e em ordem crescente a distância\n",
        "    sorted_count = sorted(tags_count.items(), reverse = True, key= lambda x: (x[1][0], -x[1][1]))\n",
        "    \n",
        "    return sorted_count[0][0] # nome da categoria com mais contagem e menos distância\n",
        "\n",
        "  def distance(self, point):\n",
        "    return list(zip(euclidean_distances(self.X, [point]), self.Y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "K9cESIsgbHqI"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv(\"titanic.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.4750</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>0.103644</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>0.3375</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>0.025374</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>0.2375</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>0.045771</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>0.015127</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "0              1         0       3   \n",
              "1              2         1       1   \n",
              "2              3         1       3   \n",
              "3              4         1       1   \n",
              "4              5         0       3   \n",
              "..           ...       ...     ...   \n",
              "886          887         0       2   \n",
              "887          888         1       1   \n",
              "888          889         0       3   \n",
              "889          890         1       1   \n",
              "890          891         0       3   \n",
              "\n",
              "                                                  Name     Sex     Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  0.2750      1   \n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  0.4750      1   \n",
              "2                               Heikkinen, Miss. Laina  female  0.3250      0   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  0.4375      1   \n",
              "4                             Allen, Mr. William Henry    male  0.4375      0   \n",
              "..                                                 ...     ...     ...    ...   \n",
              "886                              Montvila, Rev. Juozas    male  0.3375      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  0.2375      0   \n",
              "888           Johnston, Miss. Catherine Helen \"Carrie\"  female     NaN      1   \n",
              "889                              Behr, Mr. Karl Howell    male  0.3250      0   \n",
              "890                                Dooley, Mr. Patrick    male  0.4000      0   \n",
              "\n",
              "     Parch            Ticket      Fare Cabin Embarked  \n",
              "0        0         A/5 21171  0.014151   NaN        S  \n",
              "1        0          PC 17599  0.139136   C85        C  \n",
              "2        0  STON/O2. 3101282  0.015469   NaN        S  \n",
              "3        0            113803  0.103644  C123        S  \n",
              "4        0            373450  0.015713   NaN        S  \n",
              "..     ...               ...       ...   ...      ...  \n",
              "886      0            211536  0.025374   NaN        S  \n",
              "887      0            112053  0.058556   B42        S  \n",
              "888      2        W./C. 6607  0.045771   NaN        S  \n",
              "889      0            111369  0.058556  C148        C  \n",
              "890      0            370376  0.015127   NaN        Q  \n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normalizar\n",
        "for column in ['Age', 'Fare']:\n",
        "    dataframe[column] = dataframe[column]  / dataframe[column].abs().max() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CrqMxwZrKq6",
        "outputId": "a546b3b5-a647-46e6-e23b-c49e2960d830"
      },
      "outputs": [],
      "source": [
        "# Transformar a coluna 'Sex' e 'Embarked' em duas colunas\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoded_data = encoder.fit_transform(dataframe[['Sex', 'Embarked']])\n",
        "encoded_dataframe = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['Sex', 'Embarked']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "CJD57bfrsEGx"
      },
      "outputs": [],
      "source": [
        "# juntar os dataframes\n",
        "dataframe = pd.concat([dataframe, encoded_dataframe])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "# substituir valores nulos\n",
        "\n",
        "# preenche a idade com a média das idades\n",
        "dataframe['Age'] = dataframe['Age'].fillna(dataframe['Age'].mean()) \n",
        "\n",
        "#preenche o sexo com o que aparece mais vezes\n",
        "# dataframe['Sex'] = dataframe['Sex'].fillna(dataframe['Sex'].mode())\n",
        "\n",
        "# drop no 'Embarked' porque tem poucos valores NaN\n",
        "dataframe.dropna(subset='Embarked', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "vroYWl5dfQg0"
      },
      "outputs": [],
      "source": [
        "columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'] + list(encoded_dataframe.columns)\n",
        "y = ['Survived']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "y8hBhHWOltjc"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataframe[[col for col in columns]], dataframe[y], test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn = KNN()\n",
        "knn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input contains NaN.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m knn\u001b[39m.\u001b[39;49mpredict_one(X_test\u001b[39m.\u001b[39;49miloc[\u001b[39m2\u001b[39;49m]) \u001b[39m==\u001b[39m y_test\u001b[39m.\u001b[39miloc[\u001b[39m2\u001b[39m]\n",
            "Cell \u001b[1;32mIn[97], line 10\u001b[0m, in \u001b[0;36mKNN.predict_one\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_one\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 10\u001b[0m   distances \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistance(x),\u001b[39mlambda\u001b[39;00m d:d [\u001b[39m0\u001b[39m])[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk]\n\u001b[0;32m     12\u001b[0m   tags_count \u001b[39m=\u001b[39m {} \u001b[39m# {tag : (contagem , soma das distancias)}\u001b[39;00m\n\u001b[0;32m     14\u001b[0m   \u001b[39mfor\u001b[39;00m dist, tag \u001b[39min\u001b[39;00m distances:\n",
            "Cell \u001b[1;32mIn[97], line 25\u001b[0m, in \u001b[0;36mKNN.distance\u001b[1;34m(self, point)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdistance\u001b[39m(\u001b[39mself\u001b[39m, point):\n\u001b[1;32m---> 25\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(euclidean_distances(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX, [point]), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY))\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:319\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    234\u001b[0m     {\n\u001b[0;32m    235\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m     X, Y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, Y_norm_squared\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, X_norm_squared\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m ):\n\u001b[0;32m    246\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39m    Compute the distance matrix between each pair from a vector array X and Y.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39m           [1.41421356]])\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m X_norm_squared \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m         X_norm_squared \u001b[39m=\u001b[39m check_array(X_norm_squared, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:164\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    155\u001b[0m     X \u001b[39m=\u001b[39m Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    156\u001b[0m         X,\n\u001b[0;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    165\u001b[0m         X,\n\u001b[0;32m    166\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    167\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    168\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    169\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    170\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    171\u001b[0m     )\n\u001b[0;32m    172\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    173\u001b[0m         Y,\n\u001b[0;32m    174\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1044\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1045\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1049\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1050\u001b[0m         array,\n\u001b[0;32m   1051\u001b[0m         input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m   1052\u001b[0m         estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m   1053\u001b[0m         allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1054\u001b[0m     )\n\u001b[0;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m copy:\n\u001b[0;32m   1057\u001b[0m     \u001b[39mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1058\u001b[0m         \u001b[39m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    127\u001b[0m     X,\n\u001b[0;32m    128\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[0;32m    129\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[0;32m    130\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[0;32m    131\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    132\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    133\u001b[0m )\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    159\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[1;32m--> 175\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
            "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ],
      "source": [
        "knn.predict_one(X_test.iloc[2]) == y_test.iloc[2]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
